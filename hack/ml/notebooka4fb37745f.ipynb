{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport keras\nimport cv2\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import Dense,Flatten\nfrom keras.applications.inception_v3 import InceptionV3,preprocess_input\nfrom PIL import ImageFile\nfrom tensorflow.keras.utils import load_img,img_to_array\nImageFile.LOAD_TRUNCATED_IMAGES = True\nbase_model1=InceptionV3(input_shape=(256,256,3),include_top=False)\nfor layer in base_model1.layers:\n    layer.trainable=False\nx=Flatten()(base_model1.output)\nx=Dense(units=2,activation='sigmoid')(x)\nmodel1=Model(base_model1.input,x)\nmodel1.compile(optimizer='adam',loss=keras.losses.binary_crossentropy,metrics=['accuracy'])\ntrain_datagen1=ImageDataGenerator(featurewise_center=True,rotation_range=0.05,width_shift_range=0.05,horizontal_flip=True,preprocessing_function=preprocess_input,zoom_range=0.1,shear_range=0.1)\ntrain_data1=train_datagen1.flow_from_directory(directory=r'/kaggle/input/fire-dataset/fire_dataset',target_size=(256,256),batch_size=20)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-21T13:47:52.583728Z","iopub.execute_input":"2023-03-21T13:47:52.584689Z","iopub.status.idle":"2023-03-21T13:48:08.684355Z","shell.execute_reply.started":"2023-03-21T13:47:52.584644Z","shell.execute_reply":"2023-03-21T13:48:08.683194Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 1s 0us/step\nFound 999 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model1.fit(train_data1,steps_per_epoch=20,epochs=20)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T13:48:08.686980Z","iopub.execute_input":"2023-03-21T13:48:08.687753Z","iopub.status.idle":"2023-03-21T14:11:32.215287Z","shell.execute_reply.started":"2023-03-21T13:48:08.687713Z","shell.execute_reply":"2023-03-21T14:11:32.213686Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/preprocessing/image.py:1862: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  \"This ImageDataGenerator specifies \"\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n20/20 [==============================] - 49s 2s/step - loss: 0.7965 - accuracy: 0.8750\nEpoch 2/20\n20/20 [==============================] - 41s 2s/step - loss: 0.3607 - accuracy: 0.9674\nEpoch 3/20\n20/20 [==============================] - 44s 2s/step - loss: 0.2310 - accuracy: 0.9725\nEpoch 4/20\n20/20 [==============================] - 43s 2s/step - loss: 0.2021 - accuracy: 0.9725\nEpoch 5/20\n20/20 [==============================] - 43s 2s/step - loss: 0.1219 - accuracy: 0.9825\nEpoch 6/20\n20/20 [==============================] - 42s 2s/step - loss: 0.1462 - accuracy: 0.9925\nEpoch 7/20\n20/20 [==============================] - 40s 2s/step - loss: 0.1873 - accuracy: 0.9825\nEpoch 8/20\n20/20 [==============================] - 43s 2s/step - loss: 0.0842 - accuracy: 0.9925\nEpoch 9/20\n20/20 [==============================] - 40s 2s/step - loss: 0.1111 - accuracy: 0.9900\nEpoch 10/20\n20/20 [==============================] - 43s 2s/step - loss: 0.0438 - accuracy: 0.9975\nEpoch 11/20\n20/20 [==============================] - 43s 2s/step - loss: 0.2408 - accuracy: 0.9775\nEpoch 12/20\n20/20 [==============================] - 43s 2s/step - loss: 0.0973 - accuracy: 0.9875\nEpoch 13/20\n20/20 [==============================] - 41s 2s/step - loss: 0.1564 - accuracy: 0.9875\nEpoch 14/20\n20/20 [==============================] - 43s 2s/step - loss: 0.1627 - accuracy: 0.9900\nEpoch 15/20\n20/20 [==============================] - 40s 2s/step - loss: 0.0626 - accuracy: 0.9950\nEpoch 16/20\n20/20 [==============================] - 43s 2s/step - loss: 0.0926 - accuracy: 0.9925\nEpoch 17/20\n20/20 [==============================] - 43s 2s/step - loss: 0.0585 - accuracy: 0.9950\nEpoch 18/20\n20/20 [==============================] - 40s 2s/step - loss: 0.1535 - accuracy: 0.9850\nEpoch 19/20\n20/20 [==============================] - 42s 2s/step - loss: 0.1460 - accuracy: 0.9925\nEpoch 20/20\n20/20 [==============================] - 43s 2s/step - loss: 0.0993 - accuracy: 0.9900\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fda7047fcd0>"},"metadata":{}}]},{"cell_type":"code","source":"path=r'/kaggle/input/fire-testing/2022-05-26.png'\nimg=load_img(path,target_size=(256,256))\ni=img_to_array(img)\ni=preprocess_input(i)\n#if fire then output is 1 else 0\nprint(np.argmax(model1.predict(np.array([i]))))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T14:18:30.618500Z","iopub.execute_input":"2023-03-21T14:18:30.618995Z","iopub.status.idle":"2023-03-21T14:18:30.863737Z","shell.execute_reply.started":"2023-03-21T14:18:30.618958Z","shell.execute_reply":"2023-03-21T14:18:30.862677Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 131ms/step\n1\n","output_type":"stream"}]}]}